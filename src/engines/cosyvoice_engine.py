"""
CosyVoice 2.0 TTS å¼•æ“å°è£…
"""
import os
import sys
import torch
import torchaudio
from pathlib import Path
from typing import Optional, Generator

# è·å–æ ¹ç›®å½•
ROOT_DIR = Path(__file__).parent.parent.parent.absolute()
COSYVOICE_PATH = ROOT_DIR / "CosyVoice"

# åŠ¨æ€æ·»åŠ è·¯å¾„ä»¥ä¾¿å¯¼å…¥ CosyVoice
if str(COSYVOICE_PATH) not in sys.path:
    sys.path.insert(0, str(COSYVOICE_PATH))
    sys.path.insert(0, str(COSYVOICE_PATH / "third_party" / "Matcha-TTS"))

class CosyVoiceEngine:
    """CosyVoice 2.0 è‹±æ–‡TTSå¼•æ“"""
    
    def __init__(self, model_path: str, device: str = "cuda"):
        self.model_path = model_path
        self.device = device
        self._model = None
        self._loaded = False
        
    def _load_model(self):
        if not self._loaded:
            try:
                from cosyvoice.cli.cosyvoice import CosyVoice2
                import torch
                # åªæœ‰åœ¨ CUDA å¯ç”¨æ—¶æ‰å¼€å¯ fp16ï¼ŒMac(MPS)å’ŒCPUç¯å¢ƒä¸‹ä¿æŒ False ä»¥ç¡®ä¿ç»å¯¹ç¨³å®š
                use_fp16 = torch.cuda.is_available()
                
                print(f"ğŸ”„ Loading CosyVoice 2.0 on {self.device} (fp16={use_fp16})...")
                self._model = CosyVoice2(
                    self.model_path,
                    load_jit=True,
                    load_trt=False,
                    fp16=use_fp16
                )
                self._loaded = True
                print(f"âœ… CosyVoice 2.0 loaded on {self.device} (fp16={use_fp16})!")
            except Exception as e:
                print(f"âŒ Failed to load CosyVoice: {e}")
                raise
        return self._model
    
    @property
    def model(self):
        return self._load_model()
    
    @property
    def sample_rate(self) -> int:
        return self.model.sample_rate
    
    def list_voices(self) -> list:
        return self.model.list_available_spks()
    
    def synthesize(self, text: str, voice: str = "è‹±æ–‡å¥³", output_path: Optional[str] = None, stream: bool = False) -> torch.Tensor:
        audio_chunks = []
        try:
            # å¤ç”¨ synthesize_stream çš„é€»è¾‘æ¥è·å–ç”Ÿæˆå™¨ (æ³¨æ„ï¼šæµå¼è¿”å›çš„æ˜¯ bytesï¼Œè¿™é‡Œéœ€è¦æ”¹ä¸€ä¸‹æˆ–è€…é‡æ–°å®ç°é€»è¾‘)
            # ä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬æ‰‹åŠ¨å¤åˆ¶ä¸€ä¸‹é€»è¾‘ï¼Œä½†è¿™æ¬¡ä¸è½¬ bytes
            
            model = self.model
            spk_list = model.list_available_spks()

            if spk_list and voice in spk_list:
                iterable = model.inference_sft(text, voice, stream=stream)
            elif spk_list:
                print(f"âš ï¸ Voice '{voice}' not found, using preset voice: {spk_list[0]}")
                iterable = model.inference_sft(text, spk_list[0], stream=stream)
            else:
                # æ²¡æœ‰é¢„è®¾éŸ³è‰²ï¼Œç›´æ¥ä½¿ç”¨ inference_sftï¼ˆCosyVoice ä¼šä½¿ç”¨é»˜è®¤éŸ³è‰²ï¼‰
                print(f"âš ï¸ No preset voices available, using default voice via inference_sft")
                iterable = model.inference_sft(text, voice, stream=stream)

            for result in iterable:
                audio_chunks.append(result['tts_speech'])
        except Exception as e:
            import traceback
            traceback.print_exc()
            raise RuntimeError(f"CosyVoice inference failed: {e}")
        
        audio = torch.cat(audio_chunks, dim=1) if len(audio_chunks) > 1 else audio_chunks[0]
        
        if output_path:
            os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
            torchaudio.save(output_path, audio, self.sample_rate)
        return audio

    def synthesize_stream(self, text: str, voice: str = "è‹±æ–‡å¥³") -> Generator[bytes, None, None]:
        """
        æµå¼åˆæˆéŸ³é¢‘å—é€»è¾‘å†…å®¹ (æ—¥å¿—å·²ç”±ä¸Šå±‚ç»Ÿä¸€å¤„ç†)
        """
        try:
            model = self.model
            spk_list = model.list_available_spks()

            # å°è¯•ä½¿ç”¨é¢„è®¾éŸ³è‰²
            if spk_list and voice in spk_list:
                print(f"ğŸ¤ [CosyVoice] Using preset voice: {voice}")
                iterable = model.inference_sft(text, voice, stream=True)
            elif spk_list:
                # ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨çš„é¢„è®¾éŸ³è‰²
                default_voice = spk_list[0]
                print(f"âš ï¸ [CosyVoice] Voice '{voice}' not found, using preset voice: {default_voice}")
                iterable = model.inference_sft(text, default_voice, stream=True)
            else:
                # æ²¡æœ‰é¢„è®¾éŸ³è‰²ï¼Œç›´æ¥ä½¿ç”¨ inference_sftï¼ˆCosyVoice ä¼šä½¿ç”¨é»˜è®¤éŸ³è‰²ï¼‰
                print(f"âš ï¸ [CosyVoice] No preset voices available, using default voice via inference_sft")
                iterable = model.inference_sft(text, voice, stream=True)

            # æµå¼è¿­ä»£
            for chunk in iterable:
                speech = chunk['tts_speech'].numpy().flatten()
                yield speech.tobytes()

        except Exception as e:
            print(f"âŒ [CosyVoice] Streaming error: {e}")
            raise
