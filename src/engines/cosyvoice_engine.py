"""
CosyVoice TTS å¼•æ“å°è£…ï¼ˆæ”¯æŒ v2.0 å’Œ v3.0ï¼‰
ä¸å®˜æ–¹ CosyVoice 652132e ç‰ˆæœ¬ä¿æŒä¸€è‡´
"""
import os
import sys
import torch
import torchaudio
from pathlib import Path
from typing import Optional, Generator

# è·å–æ ¹ç›®å½•
ROOT_DIR = Path(__file__).parent.parent.parent.absolute()
COSYVOICE_PATH = ROOT_DIR / "CosyVoice"
MODELS_DIR = ROOT_DIR / "models"

# å¼ºåˆ¶è®¾ç½® ModelScope ç¼“å­˜ç›®å½•ï¼Œç¡®ä¿èƒ½æ‰¾åˆ° download_models.py ä¸‹è½½çš„ wetext èµ„æº
os.environ["MODELSCOPE_CACHE"] = str(MODELS_DIR)
# å¼€å¯ ModelScope ç¦»çº¿æ¨¡å¼ï¼Œç¦æ­¢è”ç½‘æ£€æŸ¥æ›´æ–°
os.environ["MODELSCOPE_OFFLINE"] = "true"

# é‡è¦ï¼šå¿…é¡»åœ¨å¯¼å…¥ CosyVoice ä¹‹å‰æ·»åŠ  Matcha-TTS è·¯å¾„
# è¿™æ ·æ‰èƒ½æ­£ç¡®å¯¼å…¥ matcha.models.components.flow_matching ç­‰æ¨¡å—
if str(COSYVOICE_PATH / "third_party" / "Matcha-TTS") not in sys.path:
    sys.path.insert(0, str(COSYVOICE_PATH / "third_party" / "Matcha-TTS"))

# ç„¶åæ·»åŠ  CosyVoice è·¯å¾„
if str(COSYVOICE_PATH) not in sys.path:
    sys.path.insert(0, str(COSYVOICE_PATH))


class CosyVoiceEngine:
    """CosyVoice TTSå¼•æ“ï¼ˆè‡ªåŠ¨æ£€æµ‹ v2.0 æˆ– v3.0ï¼‰"""

    def __init__(self, model_path: str, device: str = "cpu", trim_ref_audio_start: bool = True):
        self.model_path = model_path
        self.device = device
        self.trim_ref_audio_start = trim_ref_audio_start  # æ˜¯å¦è£å‰ªå‚è€ƒéŸ³é¢‘ç”Ÿæˆçš„å¼€å¤´
        self._model = None
        self._loaded = False
        # æ ¹æ®æ¨¡å‹è·¯å¾„åˆ¤æ–­ç‰ˆæœ¬
        self._is_v3 = "CosyVoice3" in model_path or "Fun-CosyVoice" in model_path

    def _load_model(self):
        if not self._loaded:
            try:
                import torch
                # ä¸ºäº†ä¿è¯ç”ŸæˆéŸ³é¢‘çš„æ­£ç¡®æ€§ï¼ˆé¿å…ç ´éŸ³/ä¹±ç ï¼‰ï¼Œæš‚æ—¶å¼ºåˆ¶å…³é—­ fp16
                # use_fp16 = torch.cuda.is_available()
                use_fp16 = False

                if self._is_v3:
                    from cosyvoice.cli.cosyvoice import CosyVoice3
                    print(f"ğŸ”„ Loading CosyVoice 3.0 on {self.device} (fp16={use_fp16})...")
                    self._model = CosyVoice3(
                        self.model_path,
                        load_trt=False,
                        fp16=use_fp16
                    )
                    print(f"âœ… CosyVoice 3.0 loaded on {self.device} (fp16={use_fp16})!")
                else:
                    from cosyvoice.cli.cosyvoice import CosyVoice2
                    print(f"ğŸ”„ Loading CosyVoice 2.0 on {self.device} (fp16={use_fp16})...")
                    self._model = CosyVoice2(
                        self.model_path,
                        load_jit=True,
                        load_trt=False,
                        fp16=use_fp16
                    )
                    print(f"âœ… CosyVoice 2.0 loaded on {self.device} (fp16={use_fp16})!")

                self._loaded = True
            except Exception as e:
                print(f"âŒ Failed to load CosyVoice: {e}")
                raise
        return self._model

    @property
    def model(self):
        return self._load_model()

    @property
    def sample_rate(self) -> int:
        return self.model.sample_rate

    def list_voices(self) -> list:
        return self.model.list_available_spks()

    def synthesize(self, text: str, voice: str = "è‹±æ–‡å¥³", output_path: Optional[str] = None, stream: bool = False) -> torch.Tensor:
        """
        åˆæˆè¯­éŸ³
        - å¦‚æœ voice æ˜¯é¢„è®¾éŸ³è‰²ï¼Œä½¿ç”¨ inference_sft
        - å¦åˆ™ä½¿ç”¨å‚è€ƒéŸ³é¢‘è¿›è¡Œ inference_cross_lingual
        """
        audio_chunks = []
        use_ref_audio = False

        try:
            model = self.model
            spk_list = model.list_available_spks()

            if voice in spk_list:
                # ä½¿ç”¨é¢„è®¾éŸ³è‰²
                iterable = model.inference_sft(text, voice, stream=stream)
            else:
                # ä½¿ç”¨å‚è€ƒéŸ³é¢‘è¿›è¡Œè·¨è¯­è¨€åˆæˆ
                ref_audio_path = self._find_reference_audio(voice)
                if ref_audio_path:
                    use_ref_audio = True
                    print(f"ğŸ¤ Using reference audio: {ref_audio_path}")
                    # åªåœ¨CosyVoice 3.0ä¸­æ·»åŠ è¯­è¨€æ ‡è®°
                    if self._is_v3 and not any(tag in text for tag in ['<|zh|>', '<|en|>', '<|ja|>', '<|yue|>', '<|ko|>']):
                        # ç®€å•æ£€æµ‹ï¼šå¦‚æœåŒ…å«ä¸­æ–‡å­—ç¬¦ï¼Œä½¿ç”¨ä¸­æ–‡æ ‡è®°ï¼Œå¦åˆ™ä½¿ç”¨è‹±æ–‡æ ‡è®°
                        if any('\u4e00' <= c <= '\u9fff' for c in text):
                            text = '<|zh|>' + text
                        else:
                            text = '<|en|>' + text
                    # ç›´æ¥ä¼ é€’è·¯å¾„ï¼Œå®˜æ–¹ä»£ç å†…éƒ¨ä¼šå¤„ç†åŠ è½½å’Œé‡é‡‡æ ·
                    iterable = model.inference_cross_lingual(text, ref_audio_path, stream=stream)
                else:
                    if spk_list:
                        print(f"âš ï¸ Voice '{voice}' not found, fallback to '{spk_list[0]}'")
                        iterable = model.inference_sft(text, spk_list[0], stream=stream)
                    else:
                        raise ValueError(f"Voice '{voice}' not found and no reference audio at static/voices/{voice}.wav")

            for result in iterable:
                audio_chunks.append(result['tts_speech'])

        except Exception as e:
            import traceback
            traceback.print_exc()
            raise RuntimeError(f"CosyVoice inference failed: {e}")

        audio = torch.cat(audio_chunks, dim=1) if len(audio_chunks) > 1 else audio_chunks[0]

        # è£å‰ªå¼€å¤´çš„ä½èƒ½é‡éƒ¨åˆ†ï¼ˆä¿®å¤CosyVoiceç”ŸæˆéŸ³é¢‘å¼€å¤´æœ‰é¢å¤–å†…å®¹çš„é—®é¢˜ï¼‰
        if use_ref_audio and self.trim_ref_audio_start:
            audio = self._trim_audio_start(audio)

        if output_path:
            os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
            torchaudio.save(output_path, audio, self.sample_rate)
        return audio

    def _trim_audio_start(self, audio: torch.Tensor, trim_seconds: float = 1.5) -> torch.Tensor:
        """
        è£å‰ªéŸ³é¢‘å¼€å¤´çš„å›ºå®šæ—¶é•¿ï¼ˆä¿®å¤CosyVoiceç”ŸæˆéŸ³é¢‘å¼€å¤´æœ‰é¢å¤–å†…å®¹çš„é—®é¢˜ï¼‰
        CosyVoiceåœ¨ä½¿ç”¨å‚è€ƒéŸ³é¢‘æ—¶ï¼Œä¼šåœ¨å¼€å¤´ç”Ÿæˆçº¦0.5-1.5ç§’çš„é¢å¤–å†…å®¹
        """
        trim_samples = int(trim_seconds * self.sample_rate)
        if audio.shape[1] > trim_samples:
            return audio[:, trim_samples:]
        return audio

    def synthesize_stream(self, text: str, voice: str = "è‹±æ–‡å¥³") -> Generator[bytes, None, None]:
        """
        æµå¼åˆæˆéŸ³é¢‘
        """
        try:
            model = self.model
            spk_list = model.list_available_spks()

            if voice in spk_list:
                iterable = model.inference_sft(text, voice, stream=True)
            else:
                ref_audio_path = self._find_reference_audio(voice)
                if ref_audio_path:
                    print(f"ğŸ¤ [CosyVoice] Using reference audio: {os.path.basename(ref_audio_path)}")
                    # åªåœ¨CosyVoice 3.0ä¸­æ·»åŠ è¯­è¨€æ ‡è®°
                    if self._is_v3 and not any(tag in text for tag in ['<|zh|>', '<|en|>', '<|ja|>', '<|yue|>', '<|ko|>']):
                        if any('\u4e00' <= c <= '\u9fff' for c in text):
                            text = '<|zh|>' + text
                        else:
                            text = '<|en|>' + text
                    iterable = model.inference_cross_lingual(text, ref_audio_path, stream=True)
                else:
                    print(f"âš ï¸ [CosyVoice] Voice '{voice}' not found, falling back to first available")
                    if spk_list:
                        iterable = model.inference_sft(text, spk_list[0], stream=True)
                    else:
                        raise ValueError(f"No voices available")

            for chunk in iterable:
                speech = chunk['tts_speech'].numpy().flatten()
                yield speech.tobytes()

        except Exception as e:
            print(f"âŒ [CosyVoice] Streaming error: {e}")
            raise

    def _find_reference_audio(self, voice: str) -> Optional[str]:
        """
        æŸ¥æ‰¾å‚è€ƒéŸ³é¢‘æ–‡ä»¶
        """
        # 1. ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯ç›´æ¥è·¯å¾„ï¼ˆç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹è·¯å¾„ï¼‰
        if os.path.isfile(voice):
            return voice

        voice_dir = os.path.join(ROOT_DIR, "static", "voices")

        # å°è¯•å¤šç§æ–‡ä»¶åæ ¼å¼
        candidates = [
            f"{voice.strip()}.wav",
            f"{voice.strip().replace(' ', '')}.wav",
            f"{voice.strip().lower()}.wav",
        ]

        for filename in candidates:
            path = os.path.join(voice_dir, filename)
            if os.path.exists(path):
                return path

        return None
