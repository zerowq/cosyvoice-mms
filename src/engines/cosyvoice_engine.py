"""
CosyVoice 2.0 TTS å¼•æ“å°è£…
"""
import os
import sys
import torch
import torchaudio
from pathlib import Path
from typing import Optional, Generator

# è·å–æ ¹ç›®å½•
ROOT_DIR = Path(__file__).parent.parent.parent.absolute()
COSYVOICE_PATH = ROOT_DIR / "CosyVoice"

# åŠ¨æ€æ·»åŠ è·¯å¾„ä»¥ä¾¿å¯¼å…¥ CosyVoice
if str(COSYVOICE_PATH) not in sys.path:
    sys.path.insert(0, str(COSYVOICE_PATH))
    sys.path.insert(0, str(COSYVOICE_PATH / "third_party" / "Matcha-TTS"))

class CosyVoiceEngine:
    """CosyVoice 2.0 è‹±æ–‡TTSå¼•æ“"""
    
    def __init__(self, model_path: str, device: str = "cuda"):
        self.model_path = model_path
        self.device = device
        self._model = None
        self._loaded = False
        
    def _load_model(self):
        if not self._loaded:
            try:
                from cosyvoice.cli.cosyvoice import CosyVoice2
                import torch
                # åªæœ‰åœ¨ CUDA å¯ç”¨æ—¶æ‰å¼€å¯ fp16ï¼ŒMac(MPS)å’ŒCPUç¯å¢ƒä¸‹ä¿æŒ False ä»¥ç¡®ä¿ç»å¯¹ç¨³å®š
                use_fp16 = torch.cuda.is_available()
                
                print(f"ğŸ”„ Loading CosyVoice 2.0 on {self.device} (fp16={use_fp16})...")
                self._model = CosyVoice2(
                    self.model_path,
                    load_jit=True,
                    load_trt=False,
                    fp16=use_fp16
                )
                self._loaded = True
                print(f"âœ… CosyVoice 2.0 loaded on {self.device} (fp16={use_fp16})!")
            except Exception as e:
                print(f"âŒ Failed to load CosyVoice: {e}")
                raise
        return self._model
    
    @property
    def model(self):
        return self._load_model()
    
    @property
    def sample_rate(self) -> int:
        return self.model.sample_rate
    
    def list_voices(self) -> list:
        return self.model.list_available_spks()
    
    def synthesize(self, text: str, voice: str = "è‹±æ–‡å¥³", output_path: Optional[str] = None, stream: bool = False) -> torch.Tensor:
        audio_chunks = []
        try:
            # å¤ç”¨ synthesize_stream çš„é€»è¾‘æ¥è·å–ç”Ÿæˆå™¨ (æ³¨æ„ï¼šæµå¼è¿”å›çš„æ˜¯ bytesï¼Œè¿™é‡Œéœ€è¦æ”¹ä¸€ä¸‹æˆ–è€…é‡æ–°å®ç°é€»è¾‘)
            # ä¸ºäº†ç®€å•ï¼Œæˆ‘ä»¬æ‰‹åŠ¨å¤åˆ¶ä¸€ä¸‹é€»è¾‘ï¼Œä½†è¿™æ¬¡ä¸è½¬ bytes
            
            model = self.model
            spk_list = model.list_available_spks()
            
            if voice in spk_list:
                iterable = model.inference_sft(text, voice, stream=stream)
            else:
                # å®¹é”™ï¼šå»é™¤å‰åç©ºæ ¼
                clean_voice = voice.strip().replace(" ", "").lower()
                ref_audio_path = os.path.join(ROOT_DIR, "static", "voices", f"{voice.strip()}.wav")
                
                if not os.path.exists(ref_audio_path):
                    alt_path = os.path.join(ROOT_DIR, "static", "voices", f"{clean_voice}.wav")
                    if os.path.exists(alt_path):
                        ref_audio_path = alt_path

                if os.path.exists(ref_audio_path):
                    print(f"ğŸ¤ Using local reference audio: {ref_audio_path}")
                    # ç›´æ¥ä¼ é€’è·¯å¾„å­—ç¬¦ä¸²ï¼ŒCosyVoice å†…éƒ¨ä¼šå¤„ç†åŠ è½½
                    iterable = model.inference_cross_lingual(text, ref_audio_path, stream=stream)
                else:
                    if spk_list:
                        print(f"âš ï¸ Voice '{voice}' not found, fallback to '{spk_list[0]}'")
                        iterable = model.inference_sft(text, spk_list[0], stream=stream)
                    else:
                        raise ValueError(f"Voice '{voice}' not found and no reference audio at static/voices/{voice}.wav")

            for result in iterable:
                audio_chunks.append(result['tts_speech'])
        except Exception as e:
            import traceback
            traceback.print_exc()
            raise RuntimeError(f"CosyVoice inference failed: {e}")
        
        audio = torch.cat(audio_chunks, dim=1) if len(audio_chunks) > 1 else audio_chunks[0]
        
        if output_path:
            os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
            torchaudio.save(output_path, audio, self.sample_rate)
        return audio

    def synthesize_stream(self, text: str, voice: str = "è‹±æ–‡å¥³") -> Generator[bytes, None, None]:
        """
        æµå¼åˆæˆéŸ³é¢‘å—
        æ”¯æŒé¢„è®¾éŸ³è‰²æˆ–é€šè¿‡æœ¬åœ° wav æ–‡ä»¶è¿›è¡Œ zero-shot å…‹éš†
        """
        model = self.model
        spk_list = model.list_available_spks()
        
        # 1. é¢„å¤„ç†ï¼šå»é™¤å‰åç©ºæ ¼åŠä¸­é—´ç©ºæ ¼
        clean_voice = voice.strip().replace(" ", "").lower()
        
        # 2. å¦‚æœæ˜¯é¢„è®¾éŸ³è‰²ï¼Œç›´æ¥ä½¿ç”¨ SFT æ¨ç†
        if voice in spk_list:
            iterable = model.inference_sft(text, voice, stream=True)
            
        # 3. å¦‚æœä¸æ˜¯é¢„è®¾ï¼Œä½†åœ¨ static/voices ä¸‹æœ‰åŒå wav æ–‡ä»¶ï¼Œåˆ™è¿›è¡Œ Zero-Shot æ¨ç†
        else:
            voice_dir = os.path.join(ROOT_DIR, "static", "voices")
            ref_audio_path = os.path.join(voice_dir, f"{voice.strip()}.wav")
            
            # å®¹é”™åŒ¹é…ï¼šå¦‚æœç›´æ¥æ‰¾æ‰¾ä¸åˆ°ï¼Œéå†ç›®å½•è¿›è¡Œæ¾æ•£åŒ¹é… (å¿½ç•¥ç©ºæ ¼å’Œå¤§å°å†™)
            if not os.path.exists(ref_audio_path) and os.path.exists(voice_dir):
                for f in os.listdir(voice_dir):
                    if f.lower().endswith(".wav"):
                        f_name = f.rsplit('.', 1)[0]
                        if f_name.replace(" ", "").lower() == clean_voice:
                            ref_audio_path = os.path.join(voice_dir, f)
                            break

            if os.path.exists(ref_audio_path):
                print(f"ğŸ¤ Using local reference audio: {ref_audio_path}")
                # ç›´æ¥ä¼ é€’è·¯å¾„å­—ç¬¦ä¸²
                iterable = model.inference_cross_lingual(text, ref_audio_path, stream=True)
            else:
                 # æœ€åçš„å…œåº•ï¼šå¦‚æœè¿æ–‡ä»¶éƒ½æ²¡æœ‰ï¼Œå°è¯•ç”¨ç¬¬ä¸€ä¸ªé¢„è®¾ï¼ˆå¦‚æœæœ‰ï¼‰æˆ–æŠ¥é”™
                if spk_list:
                    print(f"âš ï¸ Voice '{voice}' not found, fallback to '{spk_list[0]}'")
                    iterable = model.inference_sft(text, spk_list[0], stream=True)
                else:
                    raise ValueError(f"Voice '{voice}' not found and no reference audio at static/voices/{voice}.wav")

        for result in iterable:
            audio_tensor = result['tts_speech']
            yield audio_tensor.cpu().numpy().tobytes()
