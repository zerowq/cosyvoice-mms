"""
CosyVoice TTS å¼•æ“å°è£…ï¼ˆæ”¯æŒ v2.0 å’Œ v3.0ï¼‰
"""
import os
import sys
import torch
import torchaudio
import tempfile
import librosa
import numpy as np
from pathlib import Path
from typing import Optional, Generator

# è·å–æ ¹ç›®å½•
ROOT_DIR = Path(__file__).parent.parent.parent.absolute()
COSYVOICE_PATH = ROOT_DIR / "CosyVoice"

# åŠ¨æ€æ·»åŠ è·¯å¾„ä»¥ä¾¿å¯¼å…¥ CosyVoice
if str(COSYVOICE_PATH) not in sys.path:
    sys.path.insert(0, str(COSYVOICE_PATH))
    sys.path.insert(0, str(COSYVOICE_PATH / "third_party" / "Matcha-TTS"))


def preprocess_prompt_audio(audio_path: str, target_sr: int = 16000, max_val: float = 0.8) -> str:
    """
    é¢„å¤„ç†å‚è€ƒéŸ³é¢‘ï¼ˆä¸ Docker é•œåƒä¸­çš„ postprocess é€»è¾‘ä¸€è‡´ï¼‰
    1. å»é™¤é™éŸ³
    2. éŸ³é‡å½’ä¸€åŒ–
    3. æ·»åŠ å°¾éƒ¨é™éŸ³
    è¿”å›å¤„ç†åçš„ä¸´æ—¶æ–‡ä»¶è·¯å¾„
    """
    # åŠ è½½éŸ³é¢‘
    speech, sr = torchaudio.load(audio_path)
    speech = speech.mean(dim=0, keepdim=True)  # è½¬ä¸ºå•å£°é“

    # é‡é‡‡æ ·åˆ°ç›®æ ‡é‡‡æ ·ç‡
    if sr != target_sr:
        speech = torchaudio.transforms.Resample(orig_freq=sr, new_freq=target_sr)(speech)

    # è½¬ä¸º numpy è¿›è¡Œ librosa å¤„ç†
    speech_np = speech.numpy().flatten()

    # 1. å»é™¤é™éŸ³ (trim silence)
    speech_trimmed, _ = librosa.effects.trim(speech_np, top_db=60, frame_length=440, hop_length=220)

    # 2. éŸ³é‡å½’ä¸€åŒ–
    speech_tensor = torch.from_numpy(speech_trimmed).unsqueeze(0)
    if speech_tensor.abs().max() > max_val:
        speech_tensor = speech_tensor / speech_tensor.abs().max() * max_val

    # 3. æ·»åŠ å°¾éƒ¨é™éŸ³ (0.2ç§’)
    tail_silence = torch.zeros(1, int(target_sr * 0.2))
    speech_tensor = torch.cat([speech_tensor, tail_silence], dim=1)

    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
    temp_file = tempfile.NamedTemporaryFile(suffix='.wav', delete=False)
    torchaudio.save(temp_file.name, speech_tensor, target_sr)

    return temp_file.name

class CosyVoiceEngine:
    """CosyVoice TTSå¼•æ“ï¼ˆè‡ªåŠ¨æ£€æµ‹ v2.0 æˆ– v3.0ï¼‰"""

    def __init__(self, model_path: str, device: str = "cuda"):
        self.model_path = model_path
        self.device = device
        self._model = None
        self._loaded = False
        # æ ¹æ®æ¨¡å‹è·¯å¾„åˆ¤æ–­ç‰ˆæœ¬
        self._is_v3 = "CosyVoice3" in model_path or "Fun-CosyVoice" in model_path

    def _load_model(self):
        if not self._loaded:
            try:
                import torch
                # åªæœ‰åœ¨ CUDA å¯ç”¨æ—¶æ‰å¼€å¯ fp16
                use_fp16 = torch.cuda.is_available()

                if self._is_v3:
                    from cosyvoice.cli.cosyvoice import CosyVoice3
                    print(f"ğŸ”„ Loading CosyVoice 3.0 on {self.device} (fp16={use_fp16})...")
                    self._model = CosyVoice3(
                        self.model_path,
                        load_trt=False,
                        fp16=use_fp16
                    )
                    print(f"âœ… CosyVoice 3.0 loaded on {self.device} (fp16={use_fp16})!")
                else:
                    from cosyvoice.cli.cosyvoice import CosyVoice2
                    print(f"ğŸ”„ Loading CosyVoice 2.0 on {self.device} (fp16={use_fp16})...")
                    self._model = CosyVoice2(
                        self.model_path,
                        load_jit=True,
                        load_trt=False,
                        fp16=use_fp16
                    )
                    print(f"âœ… CosyVoice 2.0 loaded on {self.device} (fp16={use_fp16})!")

                self._loaded = True
            except Exception as e:
                print(f"âŒ Failed to load CosyVoice: {e}")
                raise
        return self._model
    
    @property
    def model(self):
        return self._load_model()
    
    @property
    def sample_rate(self) -> int:
        return self.model.sample_rate
    
    def list_voices(self) -> list:
        return self.model.list_available_spks()
    
    def synthesize(self, text: str, voice: str = "è‹±æ–‡å¥³", output_path: Optional[str] = None, stream: bool = False) -> torch.Tensor:
        audio_chunks = []
        processed_audio = None
        try:
            model = self.model
            spk_list = model.list_available_spks()

            if voice in spk_list:
                iterable = model.inference_sft(text, voice, stream=stream)
            else:
                # å®¹é”™ï¼šå»é™¤å‰åç©ºæ ¼
                clean_voice = voice.strip().replace(" ", "").lower()
                ref_audio_path = os.path.join(ROOT_DIR, "static", "voices", f"{voice.strip()}.wav")

                if not os.path.exists(ref_audio_path):
                    alt_path = os.path.join(ROOT_DIR, "static", "voices", f"{clean_voice}.wav")
                    if os.path.exists(alt_path):
                        ref_audio_path = alt_path

                if os.path.exists(ref_audio_path):
                    print(f"ğŸ¤ Using local reference audio: {ref_audio_path}")
                    # é¢„å¤„ç†å‚è€ƒéŸ³é¢‘ï¼ˆtrim silence, normalizeï¼‰
                    processed_audio = preprocess_prompt_audio(ref_audio_path)
                    iterable = model.inference_cross_lingual(text, processed_audio, stream=stream)
                else:
                    if spk_list:
                        print(f"âš ï¸ Voice '{voice}' not found, fallback to '{spk_list[0]}'")
                        iterable = model.inference_sft(text, spk_list[0], stream=stream)
                    else:
                        raise ValueError(f"Voice '{voice}' not found and no reference audio at static/voices/{voice}.wav")

            for result in iterable:
                audio_chunks.append(result['tts_speech'])
        except Exception as e:
            import traceback
            traceback.print_exc()
            raise RuntimeError(f"CosyVoice inference failed: {e}")
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if processed_audio and os.path.exists(processed_audio):
                os.unlink(processed_audio)

        audio = torch.cat(audio_chunks, dim=1) if len(audio_chunks) > 1 else audio_chunks[0]

        if output_path:
            os.makedirs(os.path.dirname(output_path) or ".", exist_ok=True)
            torchaudio.save(output_path, audio, self.sample_rate)
        return audio

    def synthesize_stream(self, text: str, voice: str = "è‹±æ–‡å¥³") -> Generator[bytes, None, None]:
        """
        æµå¼åˆæˆéŸ³é¢‘å—é€»è¾‘å†…å®¹ (æ—¥å¿—å·²ç”±ä¸Šå±‚ç»Ÿä¸€å¤„ç†)
        """
        processed_audio = None
        try:
            model = self.model
            spk_list = model.list_available_spks()

            if voice in spk_list:
                iterable = model.inference_sft(text, voice, stream=True)
            else:
                voice_dir = os.path.join(ROOT_DIR, "static", "voices")
                ref_audio_path = os.path.join(voice_dir, f"{voice.strip()}.wav")

                if os.path.exists(ref_audio_path):
                    print(f"ğŸ¤ [CosyVoice] Using reference audio: {os.path.basename(ref_audio_path)}")
                    # é¢„å¤„ç†å‚è€ƒéŸ³é¢‘ï¼ˆtrim silence, normalizeï¼‰
                    processed_audio = preprocess_prompt_audio(ref_audio_path)
                    iterable = model.inference_cross_lingual(text, processed_audio, stream=True)
                else:
                    print(f"âš ï¸ [CosyVoice] Voice '{voice}' not found, falling back to English default")
                    iterable = model.inference_sft(text, "è‹±æ–‡å¥³", stream=True)

            # æµå¼è¿­ä»£
            for chunk in iterable:
                speech = chunk['tts_speech'].numpy().flatten()
                yield speech.tobytes()

        except Exception as e:
            print(f"âŒ [CosyVoice] Streaming error: {e}")
            raise
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if processed_audio and os.path.exists(processed_audio):
                os.unlink(processed_audio)
