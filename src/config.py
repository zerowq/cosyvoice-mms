"""
TTSç³»ç»Ÿé…ç½®
"""
import os
import torch
from dataclasses import dataclass
from pathlib import Path

# è·å–é¡¹ç›®æ ¹ç›®å½•
ROOT_DIR = Path(__file__).parent.parent.absolute()

# å¼ºåˆ¶è®¾ç½® ModelScope ç¼“å­˜ç›®å½•åˆ°é¡¹ç›®å†…çš„ models ç›®å½•
os.environ["MODELSCOPE_CACHE"] = str(ROOT_DIR / "models")
# å¼ºåˆ¶å¼€å¯ç¦»çº¿æ¨¡å¼ï¼Œç¦æ­¢ä»»ä½•ç½‘ç»œè¯·æ±‚ (CI ç¯å¢ƒ/ç¦»çº¿ç”Ÿäº§å¿…é€‰)
os.environ["MODELSCOPE_OFFLINE"] = "1"
os.environ["MODELSCOPE_ENVIRONMENT"] = "local"
os.environ["HF_HUB_OFFLINE"] = "1"
os.environ["TRANSFORMERS_OFFLINE"] = "1"

# ã€ç»ˆæç¦»çº¿è¡¥ä¸ã€‘æ‹¦æˆª ModelScope çš„æ‰€æœ‰å¯èƒ½ç½‘ç»œè¯·æ±‚
def patch_environment():
    try:
        # 1. æ‹¦æˆª snapshot_download
        import modelscope.hub.snapshot_download as ms_download
        original_snapshot = ms_download.snapshot_download
        
        def mocked_snapshot(model_id, *args, **kwargs):
            if "wetext" in model_id or "cosyvoice" in model_id.lower():
                local_path = ROOT_DIR / "models" / "hub" / model_id.split('/')[-1]
                if not local_path.exists():
                     local_path = ROOT_DIR / "models" / "hub" / model_id.replace('/', os.sep)
                if "wetext" in model_id:
                    local_wetext = ROOT_DIR / "models" / "hub" / "pengzhendong" / "wetext"
                    if local_wetext.exists(): return str(local_wetext)
                if local_path.exists(): return str(local_path)
            return original_snapshot(model_id, *args, **kwargs)
        ms_download.snapshot_download = mocked_snapshot

        # 2. å½»åº•æ‹¦æˆª HubApi (ç‰ˆæœ¬æ£€æŸ¥çš„æºå¤´)
        from modelscope.hub.api import HubApi
        HubApi.login = lambda *args, **kwargs: None
        HubApi.get_model_revisions = lambda *args, **kwargs: ["master"]

        # æ£€æŸ¥å…³é”®æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™åœ¨ç¦»çº¿æ¨¡å¼ä¸‹æç¤ºé”™è¯¯
        models_dir = ROOT_DIR / "models"
        if not (models_dir / "CosyVoice2-0.5B").exists():
            print(f"âŒ CRITICAL ERROR: Model CosyVoice2-0.5B not found in {models_dir}")
            print("Please ensure models are pre-downloaded via scripts/download_models.py during build.")
    except Exception:
        pass

patch_environment()

def get_default_device():
    if torch.cuda.is_available():
        return "cuda"
    if torch.backends.mps.is_available():
        return "mps"
    return "cpu"

def get_cosyvoice_model_path():
    """è‡ªåŠ¨æ£€æµ‹å¯ç”¨çš„ CosyVoice æ¨¡å‹ï¼ˆä¼˜å…ˆä½¿ç”¨ 3.0ï¼‰"""
    v3_path = ROOT_DIR / "models" / "Fun-CosyVoice3-0.5B"
    v2_path = ROOT_DIR / "models" / "CosyVoice2-0.5B"

    if v3_path.exists():
        print(f"ğŸ¤ Using Fun-CosyVoice 3.0: {v3_path}")
        return str(v3_path)
    elif v2_path.exists():
        print(f"ğŸ¤ Using CosyVoice 2.0: {v2_path}")
        return str(v2_path)
    else:
        # é»˜è®¤è¿”å› v3 è·¯å¾„ï¼Œè®©ä¸‹è½½è„šæœ¬å¤„ç†
        return str(v3_path)

@dataclass
class TTSConfig:
    """TTSé…ç½®ç±»"""

    # æ¨¡å‹è·¯å¾„
    cosyvoice_model_path: str = None  # å°†åœ¨ __post_init__ ä¸­è®¾ç½®
    mms_model_dir: str = str(ROOT_DIR / "models")

    # è®¾å¤‡é…ç½®
    device: str = get_default_device()

    # è·¯å¾„é…ç½®
    cache_dir: str = str(ROOT_DIR / "tts_cache")
    output_dir: str = str(ROOT_DIR / "output")
    static_dir: str = str(ROOT_DIR / "static")
    log_dir: str = str(ROOT_DIR / "logs")

    # é»˜è®¤å£°éŸ³ (CosyVoice é¢„è®¾ ID é€šå¸¸ä¸ºä¸­æ–‡å‘½åï¼Œæ”¯æŒè·¨è¯­è¨€)
    default_english_voice: str = "ä¸­æ–‡å¥³"
    default_malay_voice: str = "default"

    # APIé…ç½®
    api_host: str = "0.0.0.0"
    api_port: int = 8000

    def __post_init__(self):
        # è‡ªåŠ¨æ£€æµ‹ CosyVoice æ¨¡å‹è·¯å¾„
        if self.cosyvoice_model_path is None:
            self.cosyvoice_model_path = get_cosyvoice_model_path()

        # ç¡®ä¿æ‰€æœ‰å¿…è¦ç›®å½•å­˜åœ¨
        for path in [self.cache_dir, self.output_dir, self.static_dir, self.log_dir]:
            os.makedirs(path, exist_ok=True)
        os.makedirs(os.path.join(self.static_dir, "audio"), exist_ok=True)

# å…¨å±€é…ç½®å®ä¾‹
config = TTSConfig()
